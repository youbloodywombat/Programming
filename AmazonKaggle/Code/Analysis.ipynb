{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "\n",
    "def load_data(filename, use_labels=True):\n",
    "    \"\"\"\n",
    "    Load data from CSV files and return them as numpy arrays\n",
    "    The use_labels parameter indicates whether one should\n",
    "    read the first column (containing class labels). If false,\n",
    "    return all 0s. \n",
    "    \"\"\"\n",
    "\n",
    "    # load column 1 to 8 (ignore last one)\n",
    "    data = np.loadtxt(open(\"/Users/jeffreychen/Programming/AmazonKaggle/Data/\" + filename), delimiter=',',usecols=range(1, 9), skiprows=1)\n",
    "    if use_labels:\n",
    "        labels = np.loadtxt(open(\"/Users/jeffreychen/Programming/AmazonKaggle/Data/\" + filename), delimiter=',',\n",
    "                            usecols=[0], skiprows=1)\n",
    "    else:\n",
    "        labels = np.zeros(data.shape[0])\n",
    "    return labels, data\n",
    "\n",
    "def save_results(predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,ACTION\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (i + 1, pred))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Fit models and make predictions.\n",
    "We'll use one-hot encoding to transform our categorical features\n",
    "into binary features.\n",
    "y and X will be numpy array objects.\n",
    "\"\"\"\n",
    "model = linear_model.LogisticRegression(C=3)  # the classifier we'll use\n",
    "\n",
    "# === load data in memory === #\n",
    "print \"loading data\"\n",
    "y, X = load_data('train.csv')\n",
    "y_test, X_test = load_data('test.csv', use_labels=False)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# === one-hot encoding === #\n",
    "# we want to encode the category IDs encountered both in\n",
    "# the training and the test set, so we fit the encoder on both\n",
    "\n",
    "encoder=preprocessing.OneHotEncoder()\n",
    "# np.vstack((X, X_test))\n",
    "encoder.fit(np.vstack((X, X_test)))\n",
    "# help(preprocessing.OneHotEncoder())\n",
    "X = encoder.transform(X)\n",
    "X_test = encoder.transform(X_test)\n",
    "# if you want to create new features, you'll need to compute them\n",
    "# before the encoding, and append them to your dataset after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# help(preprocessing.OneHotEncoder())\n",
    "# help(encoder.transform)\n",
    "# This will print the values and the location they are at\n",
    "# print X_test[1:10,1:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  for i in range(n):\n",
    "i=1\n",
    "SEED=5000\n",
    "# for each iteration, randomly hold out 20% of the data as CV set\n",
    "X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "    X, y, test_size=.20, random_state=i*SEED)\n",
    "\n",
    "# if you want to perform feature selection / hyperparameter\n",
    "# optimization, this is where you want to do it\n",
    "\n",
    "# train model and make predictions\n",
    "model.fit(X_train, y_train) \n",
    "model.n_iter_\n",
    "# preds = model.predict_proba(X_cv)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# help(model.fit)\n",
    "# X_test\n",
    "# help(model)\n",
    "# X_cv[:,1]\n",
    "# help(model.predict_proba)\n",
    "# print preds[1:200]\n",
    "# print y_train[1:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
